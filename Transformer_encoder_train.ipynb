{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd47a80-fbcd-480f-aacf-2fe4100897a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "link2=\"predictions_2023-07-29T02.csv\"\n",
    "link1=\"results_analysis_v1.csv\"\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371ca852-f5f1-48e5-9f5f-b5877ffd09f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datetime import datetime\n",
    "act_df = pd.read_csv(link2)\n",
    "res_df = pd.read_csv(link1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac00389-7d00-4824-a610-395ffb3d814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_feed=res_df[['medium_description_pim','HS_Code_x','Val-NoVal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb75b1ce-9181-416f-87a1-ff6f1bd418f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_feed_val= model_feed[model_feed['Val-NoVal']=='validated']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b992b8-4b98-4e13-9d6c-013ec9a91870",
   "metadata": {},
   "source": [
    "# One-Hot-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47c5041b-4fba-401b-aa9d-eceb9b8e11a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_feed_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder\n\u001b[1;32m----> 2\u001b[0m df_for_onehot \u001b[38;5;241m=\u001b[39m\u001b[43mmodel_feed_val\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHS_Code_x\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m      3\u001b[0m df_for_onehot[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex_3\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mdf_for_onehot\u001b[38;5;241m.\u001b[39mindex\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_feed_val' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "df_for_onehot =model_feed_val['HS_Code_x'].value_counts().reset_index()\n",
    "df_for_onehot['index_3']=df_for_onehot.index\n",
    "model_feed_val2=model_feed_val.merge(df_for_onehot, left_on= 'HS_Code_x', right_on='index', how='inner')\n",
    "y= model_feed_val2['index_3']\n",
    "onhe=OneHotEncoder(handle_unknown='ignore', sparse=False).fit(y.to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b01b2c-bb46-492c-98a3-202fb6ecfa10",
   "metadata": {},
   "source": [
    "Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fcef26-b911-4f50-b009-74efa400e12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca91f579-5a31-4f5c-93f6-c98700ada298",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.from_pandas(model_feed_val2)\n",
    "raw_ds=DatasetDict({'train':\n",
    "    Dataset.from_pandas(model_feed_val2)\n",
    "           \n",
    "} )\n",
    "\n",
    "split_ds=raw_ds['train'].train_test_split(test_size=0.15, shuffle=True)\n",
    "checkpoint= 'distilbert-base-cased'\n",
    "tokenizer= AutoTokenizer.from_pretrained(checkpoint)\n",
    "def tokenize_func(batch):\n",
    "    return tokenizer(batch['medium_description_pim'], truncation=True)\n",
    "token_ds= split_ds.map(tokenize_func, batched=True)\n",
    "data_collator= DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "token_ds=token_ds.remove_columns(['medium_description_pim','Val-NoVal','__index_level_0__', 'HS_Code_x_x','HS_Code_x_y', 'index'])\n",
    "token_ds=token_ds.rename_column('index_3','labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246d48c0-e2ce-4c96-9e79-95e4a3a6a6a7",
   "metadata": {},
   "source": [
    "# Create DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4335aa6f-4f44-4b8d-ac5e-6b4465a586e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a218cc0d-75ef-4bf3-b09d-aabc4e94a781",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader= DataLoader(\n",
    "token_ds['train'],\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "valid_loader= DataLoader(\n",
    "token_ds['test'],\n",
    "    shuffle=False,\n",
    "    batch_size=35,\n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa316c64-aa1d-4e84-9faf-6920fa3bdae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    for i, k in batch.items():\n",
    "        print(i)\n",
    "        print(k.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8097d8db-bb5b-4ee7-a677-3f5f3d0178b4",
   "metadata": {},
   "source": [
    "# Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b12f7b-5c38-444e-9311-fda5daa94cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cab1f40-7f63-41d4-a927-f89213201d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_customs= Encoder_Smash(\n",
    "vocab_size= tokenizer.vocab_size,\n",
    "    max_len= tokenizer.max_model_input_sizes[checkpoint],\n",
    "    d_k= 16,\n",
    "    d_model=64,\n",
    "    n_heads=4,\n",
    "    n_layers=2,\n",
    "    n_classes=351,\n",
    "    dropout_prob=0.2\n",
    ")\n",
    "model_customs.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e5a4b5-5e60-40f1-af10-0a144fa59647",
   "metadata": {},
   "source": [
    "# Optimizer & Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f528d2-9d1c-4033-9648-67d304c148ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion= torch.nn.MultiLabelSoftMarginLoss()\n",
    "optimizer= torch.optim.Adam(model_customs.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e0bc20-09e9-473f-aea0-d4c66621cf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=70\n",
    "train_losses= np.zeros(epochs)\n",
    "test_losses= np.zeros(epochs)\n",
    "best_valid_loss= np.Inf\n",
    "\n",
    "for iter1 in range(epochs):\n",
    "    model_customs.train()\n",
    "    train_loss=0.0\n",
    "    n_train=0.0\n",
    "    for batch in tqdm(train_loader):\n",
    "        batch= {k: v.to(device) for k, v in batch.items()}\n",
    "        the_number=batch['labels']\n",
    "        the_number2=np.array(the_number.cpu()).reshape(-1,1)\n",
    "        torched_labels= torch.tensor(onhe.transform(the_number2)).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs= model_customs(batch['input_ids'], batch['attention_mask'])\n",
    "        loss= criterion(outputs, torched_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss+= loss.item()*batch['input_ids'].size(0)\n",
    "        n_train += batch['input_ids'].size(0)\n",
    "\n",
    "    train_loss= train_loss/n_train\n",
    "    #Now eval\n",
    "    model_customs.eval()\n",
    "    test_loss= 0.0\n",
    "    n_test= 0.0\n",
    "\n",
    "    for batch in tqdm(valid_loader):\n",
    "        batch= {k: v.to(device) for k, v in batch.items()}\n",
    "        the_number=batch['labels']\n",
    "        the_number2=np.array(the_number.cpu()).reshape(-1,1)\n",
    "        torched_labels= torch.tensor(onhe.transform(the_number2)).to(device)\n",
    "        outputs_test= model_customs(batch['input_ids'], batch['attention_mask'])\n",
    "        loss= criterion(outputs_test, torched_labels)\n",
    "        test_loss += loss.item()*batch['input_ids'].size(0)\n",
    "        n_test += batch['input_ids'].size(0)\n",
    "    test_loss= test_loss/n_test\n",
    "\n",
    "    if test_loss< best_valid_loss:\n",
    "        torch.save(model_customs.state_dict(), 'best_model.pt')\n",
    "        best_valid_loss= test_loss\n",
    "        print('Saved weights')\n",
    "        print(iter1, train_loss, test_loss)\n",
    "    print(iter1, train_loss, test_loss)\n",
    "    train_losses[iter1]= train_loss\n",
    "    test_losses[iter1]= test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3f7601-506e-4b86-94c1-fe8074ab9e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_encoder2.load_state_dict(torch.load('best_model.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80eeb90-d691-4022-a386-1b9144af3cd2",
   "metadata": {},
   "source": [
    "# Validation Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64397643-f9a7-457c-8f07-41765606b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_correct= 0.0\n",
    "n_correct_ver2= 0.0\n",
    "n_total=0.0\n",
    "output_list=[]\n",
    "output_list_by_batch=[]\n",
    "for batch in train_loader:\n",
    "    \n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    the_number=batch['labels']\n",
    "    the_number2=np.array(the_number.cpu()).reshape(-1,1)\n",
    "    torched_labels= torch.tensor(onhe.transform(the_number2)).to(device)\n",
    "    outputs= model_customs(batch['input_ids'], batch['attention_mask'])\n",
    "    to_list=np.array(outputs.detach().cpu())\n",
    "    output_list_by_batch.append(to_list)\n",
    "    for single_out in to_list:\n",
    "        output_list.append(single_out)\n",
    "    _, predictions = torch.max(outputs,1)\n",
    "    n_correct += (predictions==batch['labels']).sum().item()\n",
    "    array3=np.array(torch.argmax(outputs, axis=1).detach().cpu())\n",
    "    array4=np.array(torch.argmax(torched_labels, axis=1).detach().cpu())\n",
    "    n_correct_ver2+= sum(array3==array4)\n",
    "    n_total += batch['labels'].shape[0]\n",
    "test_acc= n_correct/n_total\n",
    "test_acc2=n_correct_ver2/n_total\n",
    "print(f' Text acc: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673eb4b7-d59a-4cac-993c-451f4c74a91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79202a9-c696-48af-aebb-5e5164ec8237",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_correct_ver2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f829874-fd64-4d5e-8fd9-525ac0f5448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(torch.argmax(outputs, axis=1).detach().cpu())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
